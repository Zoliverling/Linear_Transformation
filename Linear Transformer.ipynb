{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy pandas torch scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier Transform for the linear transformer encoder\n",
    "class FourierTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FourierTransform, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the 2D Fourier transform to the last two dimensions\n",
    "        return torch.fft.fft2(x).real\n",
    "\n",
    "# Define the Multiplexed Attention mechanism\n",
    "\n",
    "# Define the Positionwise Feed-Forward Network\n",
    "class PositionwiseFeedforward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedforward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n",
    "\n",
    "#Encoder Layer\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.fourier_transform = FourierTransform()\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff, dropout)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        # Applying Fourier Transform as a replacement for MHA\n",
    "        src2 = self.fourier_transform(src)\n",
    "        src = self.layernorm1(src + self.dropout(src2))\n",
    "\n",
    "        # Positionwise Feedforward Network\n",
    "        src2 = self.feed_forward(src)\n",
    "        src = self.layernorm2(src + self.dropout(src2))\n",
    "\n",
    "        return src\n",
    "\n",
    "#Decoder Layer\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(TransformerDecoderLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff, dropout)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.layernorm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask, memory_mask):\n",
    "        # Self-attention on the targets\n",
    "        tgt2 = self.layernorm1(tgt)\n",
    "        tgt2 = self.self_attn(tgt2, tgt2, tgt2, attn_mask=tgt_mask)[0]\n",
    "        tgt = tgt + self.dropout(tgt2)\n",
    "\n",
    "        # Attention over encoder's output\n",
    "        tgt2 = self.layernorm2(tgt)\n",
    "        tgt2 = self.multihead_attn(tgt2, memory, memory, attn_mask=memory_mask)[0]\n",
    "        tgt = tgt + self.dropout(tgt2)\n",
    "\n",
    "        # Positionwise feedforward\n",
    "        tgt2 = self.layernorm3(tgt)\n",
    "        tgt = tgt + self.dropout(self.feed_forward(tgt2))\n",
    "        \n",
    "        return tgt\n",
    "    \n",
    "class LinearTransformer(nn.Module):\n",
    "    def __init__(self, feature_size, num_layers, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(LinearTransformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.fourier_transform = FourierTransform()  # Fourier transform layer\n",
    "        self.positional_encoder = nn.Embedding(1000, d_model)  # Customize based on max sequence length\n",
    "        self.encoder_layers = nn.ModuleList([TransformerEncoderLayer(d_model, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([TransformerDecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(d_model, feature_size)  # Adjust depending on your output size\n",
    "\n",
    "    def forward(self, src, src_mask=None, tgt=None, tgt_mask=None):\n",
    "        batch_size, seq_length, _ = src.size()\n",
    "\n",
    "        # Positional Encoding\n",
    "        positions = torch.arange(seq_length, device=src.device).unsqueeze(0).repeat(batch_size, 1)\n",
    "        src = src + self.positional_encoder(positions)\n",
    "\n",
    "        # Fourier Transform\n",
    "        src = self.fourier_transform(src)\n",
    "\n",
    "        # Encoder\n",
    "        for layer in self.encoder_layers:\n",
    "            src = layer(src, src_mask=src_mask)\n",
    "\n",
    "        if tgt is not None:\n",
    "            # If there is a target sequence (for tasks that use the decoder)\n",
    "            tgt = tgt + self.positional_encoder(positions[:tgt.size(1), :])\n",
    "            for layer in self.decoder_layers:\n",
    "                tgt = layer(tgt, src, tgt_mask=tgt_mask)\n",
    "\n",
    "            # Output layer for decoder output\n",
    "            return self.output_layer(tgt)\n",
    "\n",
    "        # Output layer to convert encoder output back to feature size (if only using the encoder)\n",
    "        return self.output_layer(src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('/Users/oli/Documents/GitHub/Linear_Trans/stock_data/TSLA.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "df.dropna(inplace=True)  # Remove NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     -0.037349\n",
       "3     -0.002483\n",
       "4     -0.002976\n",
       "5      0.012281\n",
       "6     -0.034033\n",
       "         ...   \n",
       "245    0.010482\n",
       "246    0.028777\n",
       "247    0.012084\n",
       "248   -0.022722\n",
       "249   -0.003248\n",
       "Name: log_return, Length: 248, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['log_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df['log_return'] = scaler.fit_transform(df['log_return'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a PyTorch Tensor\n",
    "data = torch.FloatTensor(df['log_return'].values).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create sequences\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your sequence length\n",
    "seq_length = 30  # Based on how many days you want to use to predict the next day\n",
    "# Create sequences\n",
    "inout_seq = create_inout_sequences(data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into train and test sets\n",
    "train_size = int(len(inout_seq) * 0.80)\n",
    "train_set = inout_seq[:train_size]\n",
    "test_set = inout_seq[train_size:]\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "model = LinearTransformer(feature_size=1, num_layers=2, d_model=64, d_ff = 2048, num_heads=8)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oli/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/oli/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([46])) that is different to the input size (torch.Size([46, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "for seq, labels in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(seq.unsqueeze(-1))  # Add an extra dimension for num_features\n",
    "    labels = labels.view(-1)  # Reshape labels to be 1D\n",
    "    single_loss = criterion(y_pred[:, -1], labels)  # Use the last value of each sequence for prediction\n",
    "    single_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11377670615911484\n"
     ]
    }
   ],
   "source": [
    "# Validate the model\n",
    "with torch.no_grad():\n",
    "    for seq, labels in test_loader:\n",
    "        y_test_pred = model(seq.unsqueeze(-1))  # Add an extra dimension for num_features\n",
    "        test_loss = criterion(y_test_pred[:, -1], labels)  # Use the last value of each sequence for prediction\n",
    "\n",
    "print(f'Test loss: {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00794637]\n",
      " [-0.00792486]\n",
      " [-0.00783756]\n",
      " [-0.00786428]\n",
      " [-0.0078784 ]\n",
      " [-0.00777479]\n",
      " [-0.00790733]\n",
      " [-0.0078891 ]\n",
      " [-0.00794543]\n",
      " [-0.00787022]\n",
      " [-0.00795936]\n",
      " [-0.00807587]\n",
      " [-0.00789444]\n",
      " [-0.00791571]\n",
      " [-0.00787331]\n",
      " [-0.00797375]\n",
      " [-0.00788428]\n",
      " [-0.0077936 ]\n",
      " [-0.00787677]\n",
      " [-0.00784591]\n",
      " [-0.00783367]\n",
      " [-0.00789612]\n",
      " [-0.00789691]\n",
      " [-0.00798001]\n",
      " [-0.00789414]\n",
      " [-0.00790479]\n",
      " [-0.00813892]\n",
      " [-0.00786941]\n",
      " [-0.00796539]\n",
      " [-0.00791902]\n",
      " [-0.00792486]\n",
      " [-0.00783756]\n",
      " [-0.00790253]\n",
      " [-0.0078784 ]\n",
      " [-0.00777479]\n",
      " [-0.00793739]\n",
      " [-0.0078891 ]\n",
      " [-0.00794543]\n",
      " [-0.00791705]\n",
      " [-0.00795936]\n",
      " [-0.00807587]\n",
      " [-0.00785621]\n",
      " [-0.00791571]\n",
      " [-0.00787331]\n",
      " [-0.00794433]\n",
      " [-0.00788428]\n",
      " [-0.0077936 ]\n",
      " [-0.00809522]\n",
      " [-0.00784591]\n",
      " [-0.00783367]\n",
      " [-0.00799772]\n",
      " [-0.00789691]\n",
      " [-0.00798001]\n",
      " [-0.00786001]\n",
      " [-0.00790479]\n",
      " [-0.00813892]\n",
      " [-0.00780191]\n",
      " [-0.00796539]\n",
      " [-0.00791902]\n",
      " [-0.00793978]\n",
      " [-0.00783756]\n",
      " [-0.00790253]\n",
      " [-0.0080568 ]\n",
      " [-0.00777479]\n",
      " [-0.00793739]\n",
      " [-0.00800719]\n",
      " [-0.00794543]\n",
      " [-0.00791705]\n",
      " [-0.00786244]\n",
      " [-0.00807587]\n",
      " [-0.00785621]\n",
      " [-0.00786909]\n",
      " [-0.00787331]\n",
      " [-0.00794433]\n",
      " [-0.00792813]\n",
      " [-0.0077936 ]\n",
      " [-0.00809522]\n",
      " [-0.00798769]\n",
      " [-0.00783367]\n",
      " [-0.00799772]\n",
      " [-0.00787116]\n",
      " [-0.00798001]\n",
      " [-0.00786001]\n",
      " [-0.00785588]\n",
      " [-0.00813892]\n",
      " [-0.00780191]\n",
      " [-0.00788392]\n",
      " [-0.00791902]\n",
      " [-0.00793978]\n",
      " [-0.00791061]\n",
      " [-0.00790253]\n",
      " [-0.0080568 ]\n",
      " [-0.00791023]\n",
      " [-0.00793739]\n",
      " [-0.00800719]\n",
      " [-0.00784486]\n",
      " [-0.00791705]\n",
      " [-0.00786244]\n",
      " [-0.00782468]\n",
      " [-0.00785621]\n",
      " [-0.00786909]\n",
      " [-0.00786856]\n",
      " [-0.00794433]\n",
      " [-0.00792813]\n",
      " [-0.00793595]\n",
      " [-0.00809522]\n",
      " [-0.00798769]\n",
      " [-0.00793069]\n",
      " [-0.00799772]\n",
      " [-0.00787116]\n",
      " [-0.00803324]\n",
      " [-0.00786001]\n",
      " [-0.00785588]\n",
      " [-0.00798067]\n",
      " [-0.00780191]\n",
      " [-0.00788392]\n",
      " [-0.00792228]\n",
      " [-0.00793978]\n",
      " [-0.00791061]\n",
      " [-0.00779304]\n",
      " [-0.0080568 ]\n",
      " [-0.00791023]\n",
      " [-0.00791465]\n",
      " [-0.00800719]\n",
      " [-0.00784486]\n",
      " [-0.00803265]\n",
      " [-0.00786244]\n",
      " [-0.00782468]\n",
      " [-0.00807859]\n",
      " [-0.00786909]\n",
      " [-0.00786856]\n",
      " [-0.0079654 ]]\n",
      "Predicted Value: [[-0.01745123]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for seq, labels in test_loader:\n",
    "        seq = seq.view(-1, 10, 1)  # Reshape your sequence data if necessary\n",
    "        y_pred_test = model(seq)\n",
    "        # Extract the last value of each sequence and reshape to 2D array\n",
    "        y_pred_test_last = y_pred_test[:, -1].numpy().reshape(-1, 1)\n",
    "        # Inverse transform the predictions\n",
    "        y_pred_test_inv = scaler.inverse_transform(y_pred_test_last)\n",
    "        predictions.extend(y_pred_test_inv)\n",
    "\n",
    "# Convert the list of predictions to a numpy array\n",
    "predictions = np.array(predictions)\n",
    "print(predictions)\n",
    "\n",
    "# To inverse transform the scaling on a single prediction value (e.g., the last prediction):\n",
    "predicted_value = scaler.inverse_transform(predictions[-1].reshape(-1, 1))\n",
    "print(f\"Predicted Value: {predicted_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price for the next time step: [173.83315]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'predicted_log_returns' is a numpy array containing your log return predictions\n",
    "# and 'last_known_price' is the last known price from your test data\n",
    "last_known_price = df['Close'].iloc[-1]\n",
    "predicted_prices = [last_known_price]\n",
    "\n",
    "\n",
    "predicted_price = predicted_prices[-1] * np.exp(predictions[0])\n",
    "predicted_prices.append(predicted_price)\n",
    "\n",
    "# The predicted price for the next time step after the last sequence in your test data\n",
    "next_predicted_price = predicted_prices[-1]\n",
    "print(f\"Predicted price for the next time step: {next_predicted_price}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
